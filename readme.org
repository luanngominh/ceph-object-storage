* Object storage with Ceph
* Provision infrastructure
** Using vagrant
 - Init three VMs run centos 7
 - Update and upgrade server
 - Tunning kernel for object storage
 - Provison: vagrant up

** Using AWS EC2
 - Terraform is prerequisite
 - Init three VMs with 5 disk sized 30GB, root disk is not included
 - Provision: go to folder terraform and type terraform up

* Install Guide
1.
useradd cephadm && echo "ji20jka" | passwd --stdin cephadm
echo "cephadm ALL = (root) NOPASSWD:ALL" | sudo tee /etc/sudoers.d/cephadm
chmod 0440 /etc/sudoers.d/cephadm
sed -i --follow-symlinks 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/sysconfig/selinux
reboot

2.
sudo su cephadm

ssh-copy-id cephadm@ceph-01.meowing.site
ssh-copy-id cephadm@ceph-02.meowing.site
ssh-copy-id cephadm@ceph-03.meowing.site

vi ~/.ssh/config
Host ceph-01
   Hostname ceph-01.meowing.site
   User cephadm
Host ceph-02
   Hostname ceph-02.meowing.site
   User cephadm
Host ceph-03
   Hostname ceph-03.meowing.site
   User cephadm

chmod 644 ~/.ssh/config

3. Install ceph deploy
   
yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm
rpm -Uvh https://download.ceph.com/rpm-nautilus/el7/noarch/ceph-release-1-1.el7.noarch.rpm
yum install python-setuptools
yum update -y && yum install ceph-deploy

4. Init ceph deploy
su cephadm
mkdir ceph_cluster
cd ceph_cluster

ceph-deploy new ceph-01 ceph-02 ceph-03
ceph-deploy install ceph-01 ceph-02 ceph-03 --release nautilus

5. create mon

ceph-deploy mon create ceph-01 ceph-02 ceph-03
ceph-deploy gatherkeys ceph-01
ceph-deploy admin ceph-01 ceph-02 ceph-03


Install mgr
ceph-deploy mgr create ceph-01 ceph-02

install dashboard
yum install -y https://download.ceph.com/rpm-nautilus/el7/noarch/ceph-mgr-dashboard-14.2.9-0.el7.noarch.rpm




6. osd
# xoa data
ceph-deploy disk zap ceph-01 /dev/xvdb
ceph-deploy disk zap ceph-01 /dev/xvdc
ceph-deploy disk zap ceph-01 /dev/xvdd
ceph-deploy disk zap ceph-01 /dev/xvde
ceph-deploy disk zap ceph-01 /dev/xvdf

# tao osd
ceph-deploy osd create --data /dev/xvdb ceph-01
ceph-deploy osd create --data /dev/xvdc ceph-01
ceph-deploy osd create --data /dev/xvdd ceph-01
ceph-deploy osd create --data /dev/xvde ceph-01
ceph-deploy osd create --data /dev/xvdf ceph-01

# xoa data
ceph-deploy disk zap ceph-02 /dev/xvdb
ceph-deploy disk zap ceph-02 /dev/xvdc
ceph-deploy disk zap ceph-02 /dev/xvdd
ceph-deploy disk zap ceph-02 /dev/xvde
ceph-deploy disk zap ceph-02 /dev/xvdf

# tao osd
ceph-deploy osd create --data /dev/xvdb ceph-02
ceph-deploy osd create --data /dev/xvdc ceph-02
ceph-deploy osd create --data /dev/xvdd ceph-02
ceph-deploy osd create --data /dev/xvde ceph-02
ceph-deploy osd create --data /dev/xvdf ceph-02

# xoa data
ceph-deploy disk zap ceph-03 /dev/xvdb
ceph-deploy disk zap ceph-03 /dev/xvdc
ceph-deploy disk zap ceph-03 /dev/xvdd
ceph-deploy disk zap ceph-03 /dev/xvde
ceph-deploy disk zap ceph-03 /dev/xvdf

# tao osd
ceph-deploy osd create --data /dev/xvdb ceph-03
ceph-deploy osd create --data /dev/xvdc ceph-03
ceph-deploy osd create --data /dev/xvdd ceph-03
ceph-deploy osd create --data /dev/xvde ceph-03
ceph-deploy osd create --data /dev/xvdf ceph-03

S3
ceph-deploy install --rgw ceph-01 ceph-02 ceph-03
ceph-deploy rgw create ceph-01 ceph-02 ceph-03

tao user
radosgw-admin user create --uid=admin --display-name=admin --system
radosgw-admin user create --uid=luanngominh --display-name=luanngominh --email=ngominhluanbox@gmail.com

ceph dashboard set-rgw-api-ssl-verify False
ceph dashboard set rgw-api-scheme http
ceph dashboard set-rgw-api-access-key xx
ceph dashboard set-rgw-api-secret-key xxx

Create pool
ceph osd pool create volume-01 168

Xoa pool
ceph config set mon mon_allow_pool_delete true

* References
  - https://min.io/resources/docs/MinIO-Throughput-Benchmarks-on-NVMe-SSD-8-Node.pdf
  - 
